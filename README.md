# Tuesday - AI Safety & Mechanistic Evaluations Research

[![Website](https://img.shields.io/badge/Website-Live-brightgreen)](https://Tuesdaythe13th.github.io/paperwithcode)
[![Google Scholar](https://img.shields.io/badge/Google%20Scholar-Profile-blue)](https://scholar.google.com/citations?user=z71m_nIAAAAJ)
[![ORCID](https://img.shields.io/badge/ORCID-0009--0002--3062--033X-green)](https://orcid.org/0009-0002-3062-033X)

**Advancing Frontier AI Safety and Mechanistic Evaluations**

Published machine learning engineer and evaluation researcher building clinically inspired diagnostics for frontier AI systems, applying biological and cognitive failure models to evaluation, red teaming, and agentic risk analysis.

 **Links:** [Linktree](https://linktr.ee/artifexlabs) | [LinkedIn](https://linkedin.com/in/artifexlabs) | [GitHub](https://github.com/Tuesdaythe13th) | [HuggingFace](https://huggingface.co/222tuesday) | [Google Scholar](https://scholar.google.com/citations?user=z71m_nIAAAAJ)

---

## About

I am committed to forging responsible, ecocentric technology frameworks. Artist/engineer with a love of the classical arts and 20 years of service in hospitality, fine arts, production design, and entertainment. Studied political science at George Washington University and grew up in NYC with world-class mentors in the music industry and fine art sales.

Currently contributing to domestic and international assurance standards in responsible tech, researching quantum systems, evaluation design, adversarial ML, experimental mechanistic interpretability techniques, and cognitive-affective modeling alongside world-class institutions including **NIST, CISA, UN ITU, Google, DeepMind, Anthropic, Humane Intelligence, Oxford, Amazon, and NVIDIA**.

**Based in:** Portland, Los Angeles, and New York (remote-first)
**Open to:** Relocation (Especially London) and other on-site roles

## Current Roles

- **Founder & Director of Research**, [ARTIFEX Labs](#artifex-labs) - AI safety, interpretability, quantum systems, advanced computing
- **Technical Contributor & Working Group Co-Founder**, [MLCommons](https://mlcommons.org) - Agentic AI, Security, AI Risk & Reliability, AILuminate, MLPerf Automotive
- **Technical Red Teamer & Safety Researcher**, [Humane Intelligence](https://humaneintelligence.org) - Multimodal red teaming, policy-relevant audits
- **Quantum Futures Research Contributor**, [Open Compute Project](https://www.opencompute.org/) (Future Technologies Initiative)
- **Independent AI/ML Engineer**, Self-Employed Consultant - Mechanistic interpretability, adversarial ML, evaluation design

## Research Focus

### AI Safety and Benchmarking
- Socio-technical risk analysis across agentic, multimodal, and quantum-adjacent systems
- Evaluation design patterning and clinical diagnostics
- SCAI risk, epistemic coercion, dissociative reasoning

### Mechanistic Interpretability
- Adversarial ML and red teaming
- Neural tracing and exploit taxonomies
- Threat modeling for frontier AI systems

### Quantum Systems & Security
- Post-quantum cryptography
- Hardware-rooted security for quantum data centers
- Quantum error correction

### Multi-Agent Systems
- Agentic maturity frameworks
- Cascade failures in recommender systems
- Multi-agent reliability and safety

## Selected Publications

- **AILuminate v1.0: AI Risk & Reliability Benchmark** (MLCommons, 2025) - [arXiv:2503.05731](https://arxiv.org/abs/2503.05731)
- **Cascade: Human-in-the-Loop Shortcomings Can Increase Risk** (FAccTRec@RecSys 2025) - [arXiv:2509.20099](https://arxiv.org/abs/2509.20099)
- **AILuminate Security: Jailbreak Benchmark v0.5** (MLCommons, 2025)
- **NIST AI 700-2: Trustworthy & Responsible AI** (NIST, 2025) - Contributing researcher
- **ARIA 0.1 Pilot Evaluation Report** (NIST, 2025) - Contributor via Humane Intelligence
- **UNESCO Red Teaming Playbook: Tackling Gender Bias** (UNESCO, 2025)
- **Beyond the Rashomon Effect** (AAAI-26, 2025) - Invited Talk
- **Beyond the Benchmark** (Stanford AIMI, 2024) - Finalist
- **Aspirational Game Play** (ACM SIGGRAPH 2024) - Invited Talk

[Full publication list ](https://scholar.google.com/citations?user=z71m_nIAAAAJ)

## Recent Achievements

-  **Winner** - UN ITU AI for Good x Princeton Challenge: 'Future Leaders in Quantum' (2025)
-  **Winner** - Humane Intelligence Bias Bounty Accessibility Challenge Set 4 (2025)
-  **Invited Talk** - AAAI-26: Beyond the Rashomon Effect (2025)
-  **Released** - MLCommons Security Jailbreak Benchmark v0.5 (2025)
-  **Announced** - MLCommons ARES for agentic systems (2025)

## ARTIFEX Labs

**ARTIFEX Labs** is an independent research and engineering laboratory focused on AI safety, security, and mechanistic accountability in complex adaptive systems. We operate at the intersection of machine learning, human factors, cybersecurity, and socio-technical risk.

### Mission
To mitigate risk and reduce harm from intelligent systems by making their internal behavior, failure modes, and socio-affective impacts legible, testable, and governable.

### 2026 Research Pillars
1. **Mechanistic Interpretability Under Deployment Conditions**
2. **Agentic AI Risk & Reliability**
3. **Behavioral & Psychological Signal Leakage**
4. **Socio-Affective Alignment & Human Impact**
5. **Standards, Benchmarks, and Public Infrastructure**

**Learn more:** [linktr.ee/artifexlabs](https://linktr.ee/artifexlabs)

### Join Us
Expression of Interest for Winter 2026 Cohort: general@artifex.fun

## Affiliations

MLCommons 路 Humane Intelligence 路 Open Compute Project (FTI) 路 Cloud Security Alliance 路 ACM 路 AAAI 路 IEEE 路 Open Source Initiative 路 Content Authenticity Initiative 路 AI for Good (ITU) 路 Environmental Defense Fund 路 IAISI 路 Algorithmic Justice League 路 WIPO 路 Young EFF 路 The Sol Foundation 路 Google Women Techmakers

## Technical Stack

**Development & ML:** Colab, Jupyter, PyTorch, TensorFlow, JAX, Hugging Face Transformers, TransformerLens, Inspect, Transluce Docent, Neuropedia
**Cloud & Scaling:** GCP (Cloud CLI, BigQuery, Vertex AI, Kubernetes), NVIDIA tools (OpenUSD)
**Agentic & Emerging:** MCP servers/extensions, agentic SDKs (AgentDevelopmentKit), evaluation/benchmark design
**Quantum Platforms:** Qbraid, Qiskit, PennyLane, IonQ, Cirq
**Languages:** Python, TypeScript, JavaScript

---

## About This Repository

This repository contains my academic website built with [Jekyll](https://jekyllrb.com/) using the [al-folio](https://github.com/alshedivat/al-folio) theme. The site features:

- Research profile and biography
- Complete publication list from Google Scholar
- Research projects including ARTIFEX Labs, AI Psychosis Research, Neural Forensic Suite, and more
- Blog posts on AI safety, mechanistic interpretability, and evaluation design
- CV and professional experience

**Live site:** [Tuesdaythe13th.github.io/paperwithcode](https://Tuesdaythe13th.github.io/paperwithcode)

## Contact

 **Email:** general@artifex.fun
 **Linktree:** [linktr.ee/artifexlabs](https://linktr.ee/artifexlabs)
 **LinkedIn:** [linkedin.com/in/artifexlabs](https://linkedin.com/in/artifexlabs)
 **GitHub:** [github.com/Tuesdaythe13th](https://github.com/Tuesdaythe13th)

---

Thank you for your time, attention, and consideration. I look forward to hearing from you!
