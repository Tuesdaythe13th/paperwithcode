---
---

@string{mlcommons = {MLCommons}}
@string{nist = {National Institute of Standards and Technology}}

@article{ailuminate2025v1,
  abbr={MLCommons},
  title={AILuminate: Introducing v1.0 of the AI Risk and Reliability Benchmark from MLCommons},
  author={Ghosh, Sujata and Frase, Haley and Williams, Adina and Luger, Sarah and RÃ¶ttger, Paul and Barez, Fazl and McGregor, Sean and Tuesday},
  journal={arXiv preprint arXiv:2503.05731},
  year={2025},
  url={https://arxiv.org/abs/2503.05731},
  arxiv={2503.05731},
  abstract={AILuminate v1.0 benchmark for assessing AI risk and reliability across frontier AI systems.},
  bibtex_show={true},
  selected={true},
  google_scholar_id={z71m_nIAAAAJ}
}

@article{cascade2025,
  abbr={RecSys},
  title={Cascade! Human in the Loop Shortcomings Can Increase the Risk of Failures in Recommender Systems},
  author={Kennedy, William M. and Shukla, Nripsuta and Patlak, Catherine and Chambers, Ben and Skeadas, Tina and Owadara, Kate and Tuesday},
  journal={arXiv preprint arXiv:2509.20099},
  year={2025},
  url={https://arxiv.org/abs/2509.20099},
  arxiv={2509.20099},
  abstract={Analysis of human-in-the-loop shortcomings and cascade failures in recommender systems.},
  bibtex_show={true},
  selected={true},
  note={FAccTRec@RecSys 2025 Workshop}
}

@techreport{ailuminate2025security,
  abbr={MLCommons},
  title={AILuminate Security: Introducing v0.5 of the Jailbreak Benchmark from MLCommons},
  author={McGregor, Sean and Barez, Fazl and Tuesday and Mattson, Peter},
  institution={MLCommons},
  year={2025},
  url={https://mlcommons.org/benchmarks/ai-safety/},
  abstract={Safety and resilience gap metrics for ISO/IEC 42001-aligned governance.},
  bibtex_show={true},
  selected={true}
}

@techreport{aria2025nist,
  abbr={NIST},
  title={Assessing Risks and Impacts of AI (ARIA): ARIA 0.1 Pilot Evaluation Report},
  author={NIST and Tuesday and Contributors},
  institution={National Institute of Standards and Technology},
  year={2025},
  url={https://www.nist.gov/itl/ai-risk-management-framework},
  abstract={NIST AI 700-2: Trustworthy & Responsible AI - Pilot evaluation report.},
  bibtex_show={true},
  note={Contributor via Humane Intelligence}
}

@techreport{agentic2025maturity,
  abbr={MLCommons},
  title={Agentic Product Maturity Ladder V0.1},
  author={McGregor, Sean and Nathani, Deepak and Saouma, Lama and Barez, Fazl and Foundjem, Armstrong and Tuesday and Gupta, Aakash and Thomas, Jake and Tashev, Vassil and Li, Tianhao and Lu, Victor and Khattak, Faiza Khan and Bankhwal, Medha and Emani, Murali and Stetson, Jacqueline and Ezick, James and Stanley, Jason and Baumann, Joachim and Gipiskis, Rokas and Iyer, Ravishankar K. and Eng, Roman and Nam, Kihyuk and Bartholomew, William and Drouin, Alexandre and Larsen, Benjamin and Shen, Chin Ze and Herde, Daniel and Chadda, Arihant and Salem, Malek Ben and Kang, Daniel and Bollacker, Kurt and Watson, Mark and Mattson, Peter},
  institution={MLCommons},
  year={2025},
  month={December},
  url={https://mlcommons.org/wp-content/uploads/2025/12/ReleaseVersion.pdf},
  abstract={The Agentic Product Maturity Ladder is a collection of benchmarks measuring the ability of agentic products to reliably support specific tasks. A system that meets reliability thresholds for a progressive sequence of principles for a specific task is considered to have climbed to a higher maturity level. This prototype maturity ladder was proposed by the MLCommons AI Risk and Reliability Working Group to inform agentic product adoption decisions and motivate reliability-focused innovation.},
  bibtex_show={true},
  selected={true}
}

@misc{unesco2025redteaming,
  abbr={UNESCO},
  title={UNESCO Red Teaming Playbook: Tackling Gender Bias and Harms in AI},
  author={UNESCO and Humane Intelligence and Tuesday and Contributors},
  year={2025},
  url={https://www.unesco.org/en/artificial-intelligence},
  abstract={Red-teaming research playbook for addressing gender bias and harms in AI systems.},
  bibtex_show={true},
  note={Red-teaming research contributor via Humane Intelligence}
}

@inproceedings{tuesday2024mental,
  abbr={Stanford},
  title={Beyond the Benchmark: Ethical AI Evaluation for Creative Communities in Mental Health},
  author={Tuesday},
  booktitle={Stanford AIMI Symposium},
  year={2024},
  note={Finalist},
  abstract={Evaluation frameworks for AI systems serving creative communities in mental health contexts.},
  bibtex_show={true}
}

@inproceedings{tuesday2024siggraph,
  abbr={SIGGRAPH},
  title={Aspirational Game Play: Improving Patient Care with AI-Powered Video Games},
  author={Tuesday},
  booktitle={ACM SIGGRAPH 2024 - Frontiers},
  year={2024},
  publisher={ACM},
  url={https://www.siggraph.org/},
  note={Invited Talk},
  abstract={Using AI-powered video games to improve patient care and outcomes.},
  bibtex_show={true}
}

@article{gatsby2014social,
  abbr={HuffPost},
  title={Social Architecture: A New Approach To Designing Social Spaces},
  author={Gatsby, C. and Tuesday},
  journal={Huffington Post},
  year={2014},
  url={https://www.huffpost.com/},
  abstract={New frameworks for designing and understanding social spaces through architectural principles.},
  bibtex_show={true}
}

@inproceedings{tuesday2025aaai,
  abbr={AAAI},
  title={Beyond the Rashomon Effect: Predictive Multiplicity in Multiagent, Multimodal, Multiobjective Systems},
  author={Tuesday},
  booktitle={39th Annual Conference on Artificial Intelligence (AAAI-26)},
  year={2025},
  note={Invited Talk},
  abstract={Exploring predictive multiplicity challenges in complex multi-agent, multimodal, and multi-objective AI systems.},
  bibtex_show={true},
  selected={true}
}
